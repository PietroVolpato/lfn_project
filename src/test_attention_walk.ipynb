{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozW3_Wc9V23z",
        "outputId": "db149fed-b48b-456d-a771-9afa0a2639a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Accedi al drive e carica la cartella AttentionWalk\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/AttentionWalk\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GvUfG6CWUz5",
        "outputId": "1186c628-71dc-4458-e1eb-309f466716bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AttentionWalk\n",
            "/content/drive/MyDrive/AttentionWalk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install texttable\n",
        "!pip install --upgrade torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4Jo8xkrXU8E",
        "outputId": "6f6a6430-3474-4361-b365-91826a30fff7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting texttable\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable\n",
            "Successfully installed texttable-1.7.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioC-dm22gf7a",
        "outputId": "00021b64-0bfa-4f63-9950-5b5118c8506a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/main.py --edge-path ./data/cit-HepTh_edges.csv --embedding-path ./result/cit-HepTh_embeddings-attention.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9MbdFJbXinS",
        "outputId": "00ec1df4-1421-4bb6-cb35-cc188eeaee72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+---------------------------------------------+\n",
            "| Attention path |     ./output/chameleon_AW_attention.csv     |\n",
            "+================+=============================================+\n",
            "| Beta           | 0.500                                       |\n",
            "+----------------+---------------------------------------------+\n",
            "| Dimensions     | 128                                         |\n",
            "+----------------+---------------------------------------------+\n",
            "| Edge path      | ./data/cit-HepTh_edges.csv                  |\n",
            "+----------------+---------------------------------------------+\n",
            "| Embedding path | ./result/cit-HepTh_embeddings-attention.csv |\n",
            "+----------------+---------------------------------------------+\n",
            "| Epochs         | 200                                         |\n",
            "+----------------+---------------------------------------------+\n",
            "| Gamma          | 0.500                                       |\n",
            "+----------------+---------------------------------------------+\n",
            "| Learning rate  | 0.010                                       |\n",
            "+----------------+---------------------------------------------+\n",
            "| Num of walks   | 80                                          |\n",
            "+----------------+---------------------------------------------+\n",
            "| Window size    | 5                                           |\n",
            "+----------------+---------------------------------------------+\n",
            "\n",
            "Caricamento del grafo iniziato.\n",
            "\n",
            "\n",
            "Calculating the feature tensor.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/AttentionWalk/src/main.py\", line 19, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/AttentionWalk/src/main.py\", line 14, in main\n",
            "    model = AttentionWalkTrainer(args)\n",
            "  File \"/content/drive/MyDrive/AttentionWalk/src/attentionwalk.py\", line 59, in __init__\n",
            "    self._initialize_model_and_data()\n",
            "  File \"/content/drive/MyDrive/AttentionWalk/src/attentionwalk.py\", line 65, in _initialize_model_and_data\n",
            "    self.target_tensor = feature_calculator(self.args, self.graph, self.device)\n",
            "  File \"/content/drive/MyDrive/AttentionWalk/src/utils.py\", line 85, in feature_calculator\n",
            "    with torch.amp.autocast(device_type=device):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\", line 226, in __init__\n",
            "    raise ValueError(\n",
            "ValueError: Expected `device_type` of type `str`, got: `<class 'torch.device'>`\n"
          ]
        }
      ]
    }
  ]
}