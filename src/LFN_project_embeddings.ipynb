{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d121cbd5",
      "metadata": {
        "id": "d121cbd5"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PietroVolpato/lfn_project/blob/main/src/LFN_project_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "358080be-e62b-4a82-b8d3-e5becb180aac",
      "metadata": {
        "id": "358080be-e62b-4a82-b8d3-e5becb180aac"
      },
      "source": [
        "# Learning from networks project\n",
        "### Evaluation of different Node Embedding algorithms\n",
        "Members:<br>\n",
        "- D'Emilio Filippo, id : 2120931\n",
        "- Volpato Pietro, id : 2120825\n",
        "\n",
        "### Information about the notebook (have a look at the report for details)\n",
        "This notebook is responsable of computing the embeddings for every embedding technique and for every selected graph.<br>\n",
        "Each computed embedding is saved to file as a numpy array (extension .npy), in the directory /embeddings. In this way that once an embedding is computed, it won't be lost when the runtime of the notebook is terminated.<br>\n",
        "We can then efficiently load the embeddings in the \"test\" notebook, and evaluate the quality of the embeddings.<br>\n",
        "Selected embedding techniques:\n",
        "- Node2Vec\n",
        "- Line\n",
        "- ...\n",
        "\n",
        "For information about the graphs, se cells below.<br>\n",
        "*NOTE*: by implementation choice, the computation of each embedding is computed separately (e.g. there are no function to coincisely compute all embeddings).<br>\n",
        "This choice comes from the fact that computing embeddings is computationally intensive, and we might want to compute only a specific\n",
        "embedding strategy for a specific graph, in order to update only this entry in the folder containing the embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb1d3b60-f774-4fc7-b0bc-7617057d6459",
      "metadata": {
        "id": "bb1d3b60-f774-4fc7-b0bc-7617057d6459"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93987c53-ecce-41d6-948b-4a4b7ac4978a",
      "metadata": {
        "id": "93987c53-ecce-41d6-948b-4a4b7ac4978a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from node2vec import Node2Vec\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gzip\n",
        "import sys\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6b64818-de78-4c30-945e-b95279c7f1c9",
      "metadata": {
        "id": "d6b64818-de78-4c30-945e-b95279c7f1c9"
      },
      "source": [
        "# configuration\n",
        "Here you can properly configure the names of the graphs and the names of the embedding strategies. Use meaningful names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e5b26d0-84d0-46ad-83dd-ac826faac4fe",
      "metadata": {
        "id": "6e5b26d0-84d0-46ad-83dd-ac826faac4fe"
      },
      "outputs": [],
      "source": [
        "graph_keys = [\"facebook\",\"citation\",\"biological\",\"CL\",\"COX2\"]\n",
        "embedding_keys = [\"LINE\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79f6ca3e-b5f5-4869-a3ef-47fb66cd7c56",
      "metadata": {
        "id": "79f6ca3e-b5f5-4869-a3ef-47fb66cd7c56"
      },
      "source": [
        "# Loading the graphs\n",
        "Selected graphs:\n",
        "- Facebook_combined    https://snap.stanford.edu/data/ego-Facebook.html          \n",
        "- cit-Helpth           https://networkrepository.com/cit-HepTh.php             \n",
        "- bio-CE-CX            https://networkrepository.com/bio-CE-CX.php             \n",
        "- CL-100K-1d8-L9       https://networkrepository.com/CL-100K-1d8-L9.php ---- the graph has node labels\n",
        "- COX2-MD              https://networkrepository.com/COX2-MD.php  ---- the graph has node labels\n",
        "\n",
        "To run this notebook, adjust the paths to match where the files are saved in your PC.<br>\n",
        "To keep paths as they are, create a \"data\" folder inside the directory of this notebook, and store the files there.<br><br>\n",
        "\n",
        "Graphs are stored as a dictionary: the key is the graph name, the value is the corresponding netowrkx graph.<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TtpPrXlsIUgJ",
      "metadata": {
        "id": "TtpPrXlsIUgJ"
      },
      "outputs": [],
      "source": [
        "facebook_path = 'data/facebook_combined.txt.gz'\n",
        "citation_path = 'data/cit-HepTh.edges'\n",
        "biological_path = 'data/bio-CE-CX.edges'\n",
        "CL_path = \"data/CL-100K-1d8-L9/CL-100K-1d8-L9.edges\"\n",
        "COX2_path = \"data/COX2-MD/COX2-MD.edges\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e83f7ed1-5bbd-4e15-8d0c-1a93e9802783",
      "metadata": {
        "id": "e83f7ed1-5bbd-4e15-8d0c-1a93e9802783"
      },
      "outputs": [],
      "source": [
        "def load_graph(path):\n",
        "    \"\"\"\n",
        "    For files with extension .edges\n",
        "    \"\"\"\n",
        "    G = nx.Graph()\n",
        "    with open(path, 'rt') as f:\n",
        "        for line in f:\n",
        "            if line.startswith('%'):  # Skip comment lines\n",
        "                continue\n",
        "            # Split the line based on spaces or commas\n",
        "            data = re.split(r'[,\\s]+', line.strip())\n",
        "            if len(data) < 2:  # Skip lines that don't have at least two columns\n",
        "                continue\n",
        "            # Extract the first two columns (nodes)\n",
        "            node1, node2 = int(data[0]), int(data[1])\n",
        "            G.add_edge(node1, node2)\n",
        "    G = nx.convert_node_labels_to_integers(G)  # Relabel nodes to integers\n",
        "    return G\n",
        "\n",
        "def load_graph_with_gz(path):\n",
        "    \"\"\"\n",
        "    For files with extension .txt.gz\n",
        "    \"\"\"\n",
        "    G = nx.Graph()\n",
        "    with gzip.open(path, 'rt') as f:\n",
        "        for line in f:\n",
        "            node1, node2 = map(int, line.strip().split())\n",
        "            G.add_edge(node1, node2)\n",
        "    G = nx.convert_node_labels_to_integers(G)  # Relabel nodes to integers\n",
        "    return G\n",
        "\n",
        "def print_graphs_info(graphs):\n",
        "    for k in graph_keys:\n",
        "        G = graphs[k]\n",
        "        print(f\"{k}: |V|={len(G.nodes)}, |E|={len(G.edges)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2ab6207-3fe1-44b0-bf8e-636a7d9f9f2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2ab6207-3fe1-44b0-bf8e-636a7d9f9f2b",
        "outputId": "b810991c-26ec-47d1-b2c3-248de16db6fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "facebook graph: |V|=4039, |E|=88234\n",
            "citation graph: |V|=22908, |E|=2444798\n",
            "biological graph: |V|=15229, |E|=245952\n",
            "CL graph: |V|=92482, |E|=436611\n",
            "COX2 graph: |V|=7962, |E|=101542\n"
          ]
        }
      ],
      "source": [
        "graphs = {}\n",
        "\n",
        "# facebook graph is the only one .tar.gz\n",
        "graphs[graph_keys[0]] = load_graph_with_gz(facebook_path)  # relabeling nodes to integer\n",
        "graphs[graph_keys[1]] = load_graph(citation_path)\n",
        "graphs[graph_keys[2]] = load_graph(biological_path)\n",
        "graphs[graph_keys[3]] = load_graph(CL_path)  # node labeled\n",
        "graphs[graph_keys[4]] = load_graph(COX2_path)  # node labeled\n",
        "\n",
        "print_graphs_info(graphs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the dataset from the GitHub repository"
      ],
      "metadata": {
        "id": "8tGjO8jcn7P5"
      },
      "id": "8tGjO8jcn7P5"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/PietroVolpato/lfn_project/main/data/\"\n",
        "filename = \"bio-CE-CX_edges.csv\"\n",
        "\n",
        "response = requests.get(url + filename)\n",
        "with open(filename, \"wb\") as file:\n",
        "    file.write(response.content)"
      ],
      "metadata": {
        "id": "pBB2zmeGoCXe"
      },
      "id": "pBB2zmeGoCXe",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f14ab17a-9328-47b5-bc28-15dbd59deabf",
      "metadata": {
        "id": "f14ab17a-9328-47b5-bc28-15dbd59deabf"
      },
      "source": [
        "# Functions and declarations for the embeddings\n",
        "Embedding data structure is defined as following:<br>\n",
        "- The first index refer to the graph (e.g. embeddings[\"facebook\"] contains the embeddings of the facebook graph for every embedding technique).<br>\n",
        "- The second index refer to the embedding technique (e.g. embeddings[\"facebook\"][\"LINE\"] cointans the embedding of facebook graph computed using LINE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e7e55ae-2aa3-4989-8903-0ccc3898309f",
      "metadata": {
        "id": "0e7e55ae-2aa3-4989-8903-0ccc3898309f"
      },
      "outputs": [],
      "source": [
        "def save(emb, path):\n",
        "    np.save(f\"embeddings/{path}.npy\", emb)\n",
        "    print(f\"Successfully saved the embeddings in embeddings/{path}.npy\")\n",
        "\n",
        "# dictionaries to store the embeddings, obtained by several techniques, for each graph\n",
        "embeddings = {}\n",
        "for k in graph_keys:\n",
        "    embeddings[k] = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66b0aada-e8df-421a-bf3a-d40c09885e40",
      "metadata": {
        "id": "66b0aada-e8df-421a-bf3a-d40c09885e40",
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "Spiegazione sui parametri di node2vec:<br>\n",
        "- G (required): The graph on which to run Node2Vec. Must be an undirected networkx.Graph object.\n",
        "- dimensions (default = 128): The dimensionality of the node embeddings. Higher dimensions allow for capturing more information but increase computational cost.\n",
        "- walk_length (default = 80): The number of steps for each random walk. A larger walk_length captures more of the network structure.\n",
        "- num_walks (default = 10): The number of random walks to start per node. Increasing this can improve the representation at the cost of additional computation.\n",
        "- workers (default = 1): The number of CPU cores to use for parallel processing. If you're running this on a multi-core machine, increasing this can speed up the computation.\n",
        "- p (return parameter): p<1: Increases the likelihood of revisiting a node (DFS-like behavior). p>1: Discourages revisiting nodes, encouraging exploration (BFS-like behavior).\n",
        "- q (in-out parameter): q<1: Encourages walks to nodes further away from the starting node (BFS-like).q>1: Biases walks to nodes closer to the starting node (DFS-like).\n",
        "\n",
        "Spiegazione di : model = node2vec.fit(window=5, min_count=1, batch_words=4)<br>\n",
        "This trains a Word2Vec model (from the gensim library) using the random walks. Let’s go over the parameters:<br>\n",
        "\n",
        "- window (default = 10): The maximum distance between the current and predicted nodes in the random walk sequence. Larger windows capture more context but require more computation.\n",
        "\n",
        "- min_count (default = 1): Minimum frequency for a node to be considered in the embedding. Since most graphs are sparse, this is often set to 1.\n",
        "\n",
        "- batch_words (default = 4): The number of words (or nodes) processed in each training batch. Adjust this for performance depending on your hardware."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7649b02-023b-4ec3-b1e7-4d051776d0f2",
      "metadata": {
        "id": "d7649b02-023b-4ec3-b1e7-4d051776d0f2"
      },
      "source": [
        "# Node2Vec\n",
        "- pip install node2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c54d5a3a-a0ff-4044-8ba4-808588927dba",
      "metadata": {
        "id": "c54d5a3a-a0ff-4044-8ba4-808588927dba"
      },
      "outputs": [],
      "source": [
        "def get_node2vec_embeddings(G, dimensions=128, walk_length=10, num_walks=20, p=1, q=1, workers=1):\n",
        "    \"\"\"\n",
        "    Generate node embeddings for a graph using the Node2Vec algorithm.\n",
        "\n",
        "    Parameters:\n",
        "        G (networkx.Graph):\n",
        "            The input graph for which embeddings are to be generated.\n",
        "            The graph should have nodes labeled as integers, ideally sequentially starting from 0.\n",
        "\n",
        "        dimensions (int, optional):\n",
        "            The dimensionality of the embedding space. Default is 128.\n",
        "\n",
        "        walk_length (int, optional):\n",
        "            The length of each random walk. Default is 10.\n",
        "\n",
        "        num_walks (int, optional):\n",
        "            The number of random walks to start from each node. Default is 20.\n",
        "\n",
        "        p (float, optional):\n",
        "            The return parameter, controlling the likelihood of immediately revisiting a node in the walk.\n",
        "            A higher value makes it more likely to backtrack. Default is 1.\n",
        "\n",
        "        q (float, optional):\n",
        "            The in-out parameter, controlling the likelihood of exploring outward from the starting node.\n",
        "            A higher value makes it more likely to move outward. Default is 1.\n",
        "\n",
        "        workers (int, optional):\n",
        "            The number of parallel workers for random walk generation and model training. Default is 1.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray:\n",
        "            A NumPy array where each row represents the embedding of a node.\n",
        "            The row index corresponds to the node ID, and each row has `dimensions` elements.\n",
        "    \"\"\"\n",
        "    # Initialize Node2Vec model\n",
        "    node2vec = Node2Vec(G, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, p=p, q=q, workers=workers)\n",
        "\n",
        "    # Fit the Node2Vec model and generate embeddings\n",
        "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
        "\n",
        "    # Convert embeddings to a NumPy array\n",
        "    num_nodes = G.number_of_nodes()\n",
        "    embeddings = np.zeros((num_nodes, dimensions))  # Preallocate array\n",
        "    for node in G.nodes:\n",
        "        embeddings[node] = model.wv[node]\n",
        "\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2535202c-086c-42ae-a7a0-2bce62d42e02",
      "metadata": {
        "id": "2535202c-086c-42ae-a7a0-2bce62d42e02"
      },
      "outputs": [],
      "source": [
        "curr = \"node2vec\"\n",
        "embeddings[graph_keys[0][curr]] = get_node2vec_embeddings(graphs[graph_keys[0]])\n",
        "save(embeddings[graph_keys[0][curr]], f\"embeddings_{graph_keys[0]}_{curr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "900c4f4c-6f35-4c15-bff0-837960ef3411",
      "metadata": {
        "id": "900c4f4c-6f35-4c15-bff0-837960ef3411"
      },
      "source": [
        "# LINE : Large-scale information network embedding\n",
        "installation guide:\n",
        "- git clone https://github.com/VahidooX/LINE.git\n",
        "- !pip install keras\n",
        "- !pip install tensorflow\n",
        "- adjust the sys.path to where you downloaded line repository\n",
        "\n",
        "*NOTE*: it was necessary to modify utils.py to adapt it at current version of keras. Some elements were deprecated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e6cc917-5939-45b8-aca5-d192cb0fd1d9",
      "metadata": {
        "id": "3e6cc917-5939-45b8-aca5-d192cb0fd1d9"
      },
      "outputs": [],
      "source": [
        "sys.path.append(r'C:\\Users\\oppil\\OneDrive\\Desktop\\Universita\\magistrale\\2_1\\LFN\\LINE')\n",
        "\n",
        "from model import create_model\n",
        "from utils import batchgen_train\n",
        "\n",
        "def get_LINE_embeddings(G, embedding_dim=128, batch_size=1024, negative_ratio=5, epochs=10, negative_sampling=\"UNIFORM\"):\n",
        "    \"\"\"\n",
        "    Generate LINE embeddings for a given graph.\n",
        "\n",
        "    Parameters:\n",
        "        G (nx.Graph): The graph for which embeddings are computed.\n",
        "        embedding_dim (int): Dimensionality of the embeddings.\n",
        "        batch_size (int): Batch size for training.\n",
        "        negative_ratio (int): Ratio of negative to positive samples.\n",
        "        epochs (int): Number of training epochs.\n",
        "        negative_sampling (str): Negative sampling strategy (\"UNIFORM\" or \"NON-UNIFORM\").\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Node embeddings (shape: [num_nodes, embedding_dim]).\n",
        "    \"\"\"\n",
        "    num_nodes = G.number_of_nodes()\n",
        "\n",
        "    # Convert networkx.Graph to adj_list (edge list as 2D numpy array)\n",
        "    adj_list = np.array(list(G.edges()), dtype=np.int32)\n",
        "\n",
        "    # Create LINE model\n",
        "    model, embed_generator = create_model(num_nodes, embedding_dim)\n",
        "\n",
        "    # Generate training batches\n",
        "    train_gen = batchgen_train(adj_list, num_nodes, batch_size, negative_ratio, negative_sampling)\n",
        "\n",
        "    # Compile and train the model\n",
        "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "    model.fit(train_gen, steps_per_epoch=500, epochs=epochs)\n",
        "\n",
        "    # Extract embeddings\n",
        "    node_ids = np.arange(num_nodes)  # Sequential node IDs\n",
        "    embeddings = embed_generator.predict_on_batch(node_ids)\n",
        "\n",
        "    print(\"Node Embeddings Shape:\", embeddings[0].shape)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32ae91dd-e0ae-47ae-b50b-42de4dfe3fb1",
      "metadata": {
        "id": "32ae91dd-e0ae-47ae-b50b-42de4dfe3fb1"
      },
      "outputs": [],
      "source": [
        "curr = \"LINE\"\n",
        "embeddings[graph_keys[0][curr]] = get_LINE_embeddings(graphs[graph_keys[0]])\n",
        "save(embeddings[graph_keys[0][curr]], f\"embeddings_{graph_keys[0]}_{curr}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8781445-1246-42e1-ac00-0cab10620d6a",
      "metadata": {
        "scrolled": true,
        "id": "e8781445-1246-42e1-ac00-0cab10620d6a"
      },
      "outputs": [],
      "source": [
        "embeddings_biological[\"LINE\"] = get_LINE_embeddings(G_biological)\n",
        "save(embeddings_biological[\"LINE\"],\"embeddings_biological_LINE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7e6cb38-7b60-44a0-a208-e32f5e4f47c7",
      "metadata": {
        "id": "f7e6cb38-7b60-44a0-a208-e32f5e4f47c7"
      },
      "outputs": [],
      "source": [
        "embeddings_CL[\"LINE\"] = get_LINE_embeddings(G_CL)\n",
        "save(embeddings_CL[\"LINE\"],\"embeddings_CL_LINE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b0134c-db53-454d-a56a-931969197e18",
      "metadata": {
        "id": "44b0134c-db53-454d-a56a-931969197e18"
      },
      "outputs": [],
      "source": [
        "embeddings_citation[\"LINE\"] = get_LINE_embeddings(G_citation)\n",
        "save(embeddings_citation[\"LINE\"],\"embeddings_citation_LINE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17d14519-2db5-404a-a52d-45645752aa7c",
      "metadata": {
        "id": "17d14519-2db5-404a-a52d-45645752aa7c"
      },
      "outputs": [],
      "source": [
        "embeddings_COX2[\"LINE\"] = get_LINE_embeddings(G_COX2)\n",
        "save(embeddings_COX2[\"LINE\"],\"embeddings_COX2_LINE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5abc4a49",
      "metadata": {
        "id": "5abc4a49"
      },
      "source": [
        "# AttentionWalk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f540988",
      "metadata": {
        "id": "5f540988"
      },
      "source": [
        "## Installation guide\n",
        "<ol>\n",
        "<li>git clone https://github.com/benedekrozemberczki/AttentionWalk.git</li>\n",
        "<li>pip install texttable==1.6.7</li>\n",
        "</ol>\n",
        "\n",
        "It requires that the input file is a .csv, so first we have implemented a function that converts the .txt.gz and the .edges files to a .csv to be given as input to the AttentionWalk algorithm.<br>\n",
        "For starting the algorithm you have to enter to the AttentionWalk folder after having cloned it from the Github repository and then set the arguments as described in the README.md file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a3b872e0",
      "metadata": {
        "id": "a3b872e0",
        "outputId": "44fa23c4-3512-4e6c-e2e7-4459f560804d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AttentionWalk'...\n",
            "remote: Enumerating objects: 284, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 284 (delta 21), reused 9 (delta 7), pack-reused 246 (from 1)\u001b[K\n",
            "Receiving objects: 100% (284/284), 1.26 MiB | 12.28 MiB/s, done.\n",
            "Resolving deltas: 100% (162/162), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/benedekrozemberczki/AttentionWalk.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7d33c074",
      "metadata": {
        "id": "7d33c074",
        "outputId": "bdb2c444-b76b-4596-af4b-f60315b0747e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting texttable==1.6.7\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: texttable\n",
            "Successfully installed texttable-1.6.7\n"
          ]
        }
      ],
      "source": [
        "!pip install texttable==1.6.7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir result"
      ],
      "metadata": {
        "id": "EsNlqP00olSN"
      },
      "id": "EsNlqP00olSN",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d01b0bbb",
      "metadata": {
        "id": "d01b0bbb"
      },
      "source": [
        "## Test with the facebook network\n",
        "Save the embeddings in the result folder with also the attention path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98fc24b7",
      "metadata": {
        "id": "98fc24b7",
        "outputId": "80702d2f-f99e-402c-a944-b6dcc8ab5146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------+------------------------------------------------+\n",
            "| Attention path |      ../../result/facebook_attention.csv       |\n",
            "+================+================================================+\n",
            "| Beta           | 0.500                                          |\n",
            "+----------------+------------------------------------------------+\n",
            "| Dimensions     | 128                                            |\n",
            "+----------------+------------------------------------------------+\n",
            "| Edge path      | ../../data/facebook_edges.csv                  |\n",
            "+----------------+------------------------------------------------+\n",
            "| Embedding path | ../../result/facebook_embeddings_attention.csv |\n",
            "+----------------+------------------------------------------------+\n",
            "| Epochs         | 176                                            |\n",
            "+----------------+------------------------------------------------+\n",
            "| Gamma          | 0.500                                          |\n",
            "+----------------+------------------------------------------------+\n",
            "| Learning rate  | 0.010                                          |\n",
            "+----------------+------------------------------------------------+\n",
            "| Num of walks   | 80                                             |\n",
            "+----------------+------------------------------------------------+\n",
            "| Window size    | 5                                              |\n",
            "+----------------+------------------------------------------------+\n",
            "\n",
            "Target matrix creation started.\n",
            "\n",
            "\n",
            "Training the model.\n",
            "\n",
            "\n",
            "Saving the model.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Adjacency matrix powers:   0%|          | 0/4 [00:00<?, ?it/s]\n",
            "Adjacency matrix powers:  25%|██▌       | 1/4 [00:00<00:00,  6.29it/s]\n",
            "Adjacency matrix powers:  50%|█████     | 2/4 [00:01<00:01,  1.64it/s]\n",
            "Adjacency matrix powers:  75%|███████▌  | 3/4 [00:03<00:01,  1.51s/it]\n",
            "Adjacency matrix powers: 100%|██████████| 4/4 [00:07<00:00,  2.59s/it]\n",
            "Adjacency matrix powers: 100%|██████████| 4/4 [00:07<00:00,  1.98s/it]\n",
            "\n",
            "Loss:   0%|          | 0/176 [00:00<?, ?it/s]\n",
            "Attention Walk (Loss=48.3163):   0%|          | 0/176 [00:01<?, ?it/s]\n",
            "Attention Walk (Loss=48.3163):   1%|          | 1/176 [00:01<04:58,  1.71s/it]\n",
            "Attention Walk (Loss=48.3045):   1%|          | 1/176 [00:03<04:58,  1.71s/it]\n",
            "Attention Walk (Loss=48.3045):   1%|          | 2/176 [00:03<04:35,  1.58s/it]\n",
            "Attention Walk (Loss=48.1248):   1%|          | 2/176 [00:04<04:35,  1.58s/it]\n",
            "Attention Walk (Loss=48.1248):   2%|▏         | 3/176 [00:04<04:19,  1.50s/it]\n",
            "Attention Walk (Loss=47.8208):   2%|▏         | 3/176 [00:05<04:19,  1.50s/it]\n",
            "Attention Walk (Loss=47.8208):   2%|▏         | 4/176 [00:05<04:09,  1.45s/it]\n",
            "Attention Walk (Loss=47.3098):   2%|▏         | 4/176 [00:07<04:09,  1.45s/it]\n",
            "Attention Walk (Loss=47.3098):   3%|▎         | 5/176 [00:07<04:15,  1.49s/it]\n",
            "Attention Walk (Loss=46.5573):   3%|▎         | 5/176 [00:09<04:15,  1.49s/it]\n",
            "Attention Walk (Loss=46.5573):   3%|▎         | 6/176 [00:09<04:11,  1.48s/it]\n",
            "Attention Walk (Loss=45.5486):   3%|▎         | 6/176 [00:10<04:11,  1.48s/it]\n",
            "Attention Walk (Loss=45.5486):   4%|▍         | 7/176 [00:10<04:06,  1.46s/it]\n",
            "Attention Walk (Loss=44.2709):   4%|▍         | 7/176 [00:11<04:06,  1.46s/it]\n",
            "Attention Walk (Loss=44.2709):   5%|▍         | 8/176 [00:11<04:01,  1.44s/it]\n",
            "Attention Walk (Loss=42.717):   5%|▍         | 8/176 [00:13<04:01,  1.44s/it] \n",
            "Attention Walk (Loss=42.717):   5%|▌         | 9/176 [00:13<04:01,  1.45s/it]\n",
            "Attention Walk (Loss=40.8895):   5%|▌         | 9/176 [00:16<04:01,  1.45s/it]\n",
            "Attention Walk (Loss=40.8895):   6%|▌         | 10/176 [00:16<05:29,  1.98s/it]\n",
            "Attention Walk (Loss=38.8018):   6%|▌         | 10/176 [00:17<05:29,  1.98s/it]\n",
            "Attention Walk (Loss=38.8018):   6%|▋         | 11/176 [00:17<04:51,  1.77s/it]\n",
            "Attention Walk (Loss=36.478):   6%|▋         | 11/176 [00:18<04:51,  1.77s/it] \n",
            "Attention Walk (Loss=36.478):   7%|▋         | 12/176 [00:18<04:18,  1.57s/it]\n",
            "Attention Walk (Loss=33.9533):   7%|▋         | 12/176 [00:20<04:18,  1.57s/it]\n",
            "Attention Walk (Loss=33.9533):   7%|▋         | 13/176 [00:20<03:55,  1.45s/it]\n",
            "Attention Walk (Loss=31.2737):   7%|▋         | 13/176 [00:21<03:55,  1.45s/it]\n",
            "Attention Walk (Loss=31.2737):   8%|▊         | 14/176 [00:21<03:40,  1.36s/it]\n",
            "Attention Walk (Loss=28.4949):   8%|▊         | 14/176 [00:22<03:40,  1.36s/it]\n",
            "Attention Walk (Loss=28.4949):   9%|▊         | 15/176 [00:22<03:31,  1.31s/it]\n",
            "Attention Walk (Loss=25.6801):   9%|▊         | 15/176 [00:23<03:31,  1.31s/it]\n",
            "Attention Walk (Loss=25.6801):   9%|▉         | 16/176 [00:23<03:31,  1.32s/it]\n",
            "Attention Walk (Loss=22.8967):   9%|▉         | 16/176 [00:24<03:31,  1.32s/it]\n",
            "Attention Walk (Loss=22.8967):  10%|▉         | 17/176 [00:24<03:27,  1.31s/it]\n",
            "Attention Walk (Loss=20.2111):  10%|▉         | 17/176 [00:26<03:27,  1.31s/it]\n",
            "Attention Walk (Loss=20.2111):  10%|█         | 18/176 [00:26<03:24,  1.29s/it]\n",
            "Attention Walk (Loss=17.6837):  10%|█         | 18/176 [00:27<03:24,  1.29s/it]\n",
            "Attention Walk (Loss=17.6837):  11%|█         | 19/176 [00:27<03:20,  1.27s/it]\n",
            "Attention Walk (Loss=15.3633):  11%|█         | 19/176 [00:28<03:20,  1.27s/it]\n",
            "Attention Walk (Loss=15.3633):  11%|█▏        | 20/176 [00:28<03:15,  1.26s/it]\n",
            "Attention Walk (Loss=13.2834):  11%|█▏        | 20/176 [00:29<03:15,  1.26s/it]\n",
            "Attention Walk (Loss=13.2834):  12%|█▏        | 21/176 [00:29<03:09,  1.22s/it]\n",
            "Attention Walk (Loss=11.4599):  12%|█▏        | 21/176 [00:30<03:09,  1.22s/it]\n",
            "Attention Walk (Loss=11.4599):  12%|█▎        | 22/176 [00:30<03:03,  1.19s/it]\n",
            "Attention Walk (Loss=9.8926):  12%|█▎        | 22/176 [00:32<03:03,  1.19s/it] \n",
            "Attention Walk (Loss=9.8926):  13%|█▎        | 23/176 [00:32<02:59,  1.17s/it]\n",
            "Attention Walk (Loss=8.5678):  13%|█▎        | 23/176 [00:33<02:59,  1.17s/it]\n",
            "Attention Walk (Loss=8.5678):  14%|█▎        | 24/176 [00:33<02:55,  1.16s/it]\n",
            "Attention Walk (Loss=7.4626):  14%|█▎        | 24/176 [00:34<02:55,  1.16s/it]\n",
            "Attention Walk (Loss=7.4626):  14%|█▍        | 25/176 [00:34<02:51,  1.13s/it]\n",
            "Attention Walk (Loss=6.5492):  14%|█▍        | 25/176 [00:35<02:51,  1.13s/it]\n",
            "Attention Walk (Loss=6.5492):  15%|█▍        | 26/176 [00:35<02:47,  1.11s/it]\n",
            "Attention Walk (Loss=5.7991):  15%|█▍        | 26/176 [00:36<02:47,  1.11s/it]\n",
            "Attention Walk (Loss=5.7991):  15%|█▌        | 27/176 [00:36<02:42,  1.09s/it]\n",
            "Attention Walk (Loss=5.185):  15%|█▌        | 27/176 [00:37<02:42,  1.09s/it] \n",
            "Attention Walk (Loss=5.185):  16%|█▌        | 28/176 [00:37<02:39,  1.08s/it]\n",
            "Attention Walk (Loss=4.6827):  16%|█▌        | 28/176 [00:38<02:39,  1.08s/it]\n",
            "Attention Walk (Loss=4.6827):  16%|█▋        | 29/176 [00:38<02:36,  1.07s/it]\n",
            "Attention Walk (Loss=4.2717):  16%|█▋        | 29/176 [00:39<02:36,  1.07s/it]\n",
            "Attention Walk (Loss=4.2717):  17%|█▋        | 30/176 [00:39<02:35,  1.07s/it]\n",
            "Attention Walk (Loss=3.9347):  17%|█▋        | 30/176 [00:40<02:35,  1.07s/it]\n",
            "Attention Walk (Loss=3.9347):  18%|█▊        | 31/176 [00:40<02:33,  1.06s/it]\n",
            "Attention Walk (Loss=3.6577):  18%|█▊        | 31/176 [00:41<02:33,  1.06s/it]\n",
            "Attention Walk (Loss=3.6577):  18%|█▊        | 32/176 [00:41<02:32,  1.06s/it]\n",
            "Attention Walk (Loss=3.4295):  18%|█▊        | 32/176 [00:42<02:32,  1.06s/it]\n",
            "Attention Walk (Loss=3.4295):  19%|█▉        | 33/176 [00:42<02:28,  1.04s/it]\n",
            "Attention Walk (Loss=3.2409):  19%|█▉        | 33/176 [00:43<02:28,  1.04s/it]\n",
            "Attention Walk (Loss=3.2409):  19%|█▉        | 34/176 [00:43<02:25,  1.02s/it]\n",
            "Attention Walk (Loss=3.0845):  19%|█▉        | 34/176 [00:44<02:25,  1.02s/it]\n",
            "Attention Walk (Loss=3.0845):  20%|█▉        | 35/176 [00:44<02:24,  1.02s/it]\n",
            "Attention Walk (Loss=2.9545):  20%|█▉        | 35/176 [00:45<02:24,  1.02s/it]\n",
            "Attention Walk (Loss=2.9545):  20%|██        | 36/176 [00:45<02:23,  1.03s/it]\n",
            "Attention Walk (Loss=2.8461):  20%|██        | 36/176 [00:46<02:23,  1.03s/it]\n",
            "Attention Walk (Loss=2.8461):  21%|██        | 37/176 [00:46<02:22,  1.03s/it]\n",
            "Attention Walk (Loss=2.7554):  21%|██        | 37/176 [00:47<02:22,  1.03s/it]\n",
            "Attention Walk (Loss=2.7554):  22%|██▏       | 38/176 [00:47<02:21,  1.02s/it]\n",
            "Attention Walk (Loss=2.6792):  22%|██▏       | 38/176 [00:48<02:21,  1.02s/it]\n",
            "Attention Walk (Loss=2.6792):  22%|██▏       | 39/176 [00:48<02:21,  1.04s/it]\n",
            "Attention Walk (Loss=2.6149):  22%|██▏       | 39/176 [00:49<02:21,  1.04s/it]\n",
            "Attention Walk (Loss=2.6149):  23%|██▎       | 40/176 [00:49<02:19,  1.03s/it]\n",
            "Attention Walk (Loss=2.5605):  23%|██▎       | 40/176 [00:50<02:19,  1.03s/it]\n",
            "Attention Walk (Loss=2.5605):  23%|██▎       | 41/176 [00:50<02:18,  1.03s/it]\n",
            "Attention Walk (Loss=2.5141):  23%|██▎       | 41/176 [00:51<02:18,  1.03s/it]\n",
            "Attention Walk (Loss=2.5141):  24%|██▍       | 42/176 [00:51<02:16,  1.02s/it]\n",
            "Attention Walk (Loss=2.4743):  24%|██▍       | 42/176 [00:52<02:16,  1.02s/it]\n",
            "Attention Walk (Loss=2.4743):  24%|██▍       | 43/176 [00:52<02:16,  1.02s/it]\n",
            "Attention Walk (Loss=2.44):  24%|██▍       | 43/176 [00:53<02:16,  1.02s/it]  \n",
            "Attention Walk (Loss=2.44):  25%|██▌       | 44/176 [00:53<02:16,  1.04s/it]\n",
            "Attention Walk (Loss=2.4101):  25%|██▌       | 44/176 [00:55<02:16,  1.04s/it]\n",
            "Attention Walk (Loss=2.4101):  26%|██▌       | 45/176 [00:55<02:17,  1.05s/it]\n",
            "Attention Walk (Loss=2.384):  26%|██▌       | 45/176 [00:56<02:17,  1.05s/it] \n",
            "Attention Walk (Loss=2.384):  26%|██▌       | 46/176 [00:56<02:15,  1.04s/it]\n",
            "Attention Walk (Loss=2.3609):  26%|██▌       | 46/176 [00:57<02:15,  1.04s/it]\n",
            "Attention Walk (Loss=2.3609):  27%|██▋       | 47/176 [00:57<02:15,  1.05s/it]\n",
            "Attention Walk (Loss=2.3402):  27%|██▋       | 47/176 [00:58<02:15,  1.05s/it]\n",
            "Attention Walk (Loss=2.3402):  27%|██▋       | 48/176 [00:58<02:12,  1.04s/it]\n",
            "Attention Walk (Loss=2.3217):  27%|██▋       | 48/176 [00:59<02:12,  1.04s/it]\n",
            "Attention Walk (Loss=2.3217):  28%|██▊       | 49/176 [00:59<02:14,  1.06s/it]\n",
            "Attention Walk (Loss=2.3049):  28%|██▊       | 49/176 [01:00<02:14,  1.06s/it]\n",
            "Attention Walk (Loss=2.3049):  28%|██▊       | 50/176 [01:00<02:20,  1.12s/it]\n",
            "Attention Walk (Loss=2.2894):  28%|██▊       | 50/176 [01:02<02:20,  1.12s/it]\n",
            "Attention Walk (Loss=2.2894):  29%|██▉       | 51/176 [01:02<02:49,  1.36s/it]\n",
            "Attention Walk (Loss=2.2752):  29%|██▉       | 51/176 [01:04<02:49,  1.36s/it]\n",
            "Attention Walk (Loss=2.2752):  30%|██▉       | 52/176 [01:04<02:57,  1.44s/it]\n",
            "Attention Walk (Loss=2.262):  30%|██▉       | 52/176 [01:05<02:57,  1.44s/it] \n",
            "Attention Walk (Loss=2.262):  30%|███       | 53/176 [01:05<03:02,  1.48s/it]\n",
            "Attention Walk (Loss=2.2496):  30%|███       | 53/176 [01:07<03:02,  1.48s/it]\n",
            "Attention Walk (Loss=2.2496):  31%|███       | 54/176 [01:07<03:00,  1.48s/it]\n",
            "Attention Walk (Loss=2.2379):  31%|███       | 54/176 [01:08<03:00,  1.48s/it]\n",
            "Attention Walk (Loss=2.2379):  31%|███▏      | 55/176 [01:08<03:06,  1.54s/it]\n",
            "Attention Walk (Loss=2.2268):  31%|███▏      | 55/176 [01:10<03:06,  1.54s/it]\n",
            "Attention Walk (Loss=2.2268):  32%|███▏      | 56/176 [01:10<03:10,  1.59s/it]\n",
            "Attention Walk (Loss=2.2163):  32%|███▏      | 56/176 [01:11<03:10,  1.59s/it]\n",
            "Attention Walk (Loss=2.2163):  32%|███▏      | 57/176 [01:11<02:57,  1.49s/it]\n",
            "Attention Walk (Loss=2.2062):  32%|███▏      | 57/176 [01:13<02:57,  1.49s/it]\n",
            "Attention Walk (Loss=2.2062):  33%|███▎      | 58/176 [01:13<02:50,  1.44s/it]\n",
            "Attention Walk (Loss=2.1966):  33%|███▎      | 58/176 [01:14<02:50,  1.44s/it]\n",
            "Attention Walk (Loss=2.1966):  34%|███▎      | 59/176 [01:14<02:57,  1.52s/it]\n",
            "Attention Walk (Loss=2.1874):  34%|███▎      | 59/176 [01:16<02:57,  1.52s/it]\n",
            "Attention Walk (Loss=2.1874):  34%|███▍      | 60/176 [01:16<02:52,  1.48s/it]\n",
            "Attention Walk (Loss=2.1785):  34%|███▍      | 60/176 [01:17<02:52,  1.48s/it]\n",
            "Attention Walk (Loss=2.1785):  35%|███▍      | 61/176 [01:17<02:44,  1.43s/it]\n",
            "Attention Walk (Loss=2.1699):  35%|███▍      | 61/176 [01:18<02:44,  1.43s/it]\n",
            "Attention Walk (Loss=2.1699):  35%|███▌      | 62/176 [01:18<02:40,  1.41s/it]\n",
            "Attention Walk (Loss=2.1616):  35%|███▌      | 62/176 [01:20<02:40,  1.41s/it]\n",
            "Attention Walk (Loss=2.1616):  36%|███▌      | 63/176 [01:20<02:34,  1.37s/it]\n",
            "Attention Walk (Loss=2.1535):  36%|███▌      | 63/176 [01:21<02:34,  1.37s/it]\n",
            "Attention Walk (Loss=2.1535):  36%|███▋      | 64/176 [01:21<02:29,  1.34s/it]\n",
            "Attention Walk (Loss=2.1458):  36%|███▋      | 64/176 [01:22<02:29,  1.34s/it]\n",
            "Attention Walk (Loss=2.1458):  37%|███▋      | 65/176 [01:22<02:24,  1.30s/it]\n",
            "Attention Walk (Loss=2.1382):  37%|███▋      | 65/176 [01:23<02:24,  1.30s/it]\n",
            "Attention Walk (Loss=2.1382):  38%|███▊      | 66/176 [01:23<02:19,  1.27s/it]\n",
            "Attention Walk (Loss=2.1309):  38%|███▊      | 66/176 [01:24<02:19,  1.27s/it]\n",
            "Attention Walk (Loss=2.1309):  38%|███▊      | 67/176 [01:24<02:14,  1.24s/it]\n",
            "Attention Walk (Loss=2.1238):  38%|███▊      | 67/176 [01:26<02:14,  1.24s/it]\n",
            "Attention Walk (Loss=2.1238):  39%|███▊      | 68/176 [01:26<02:11,  1.22s/it]\n",
            "Attention Walk (Loss=2.117):  39%|███▊      | 68/176 [01:27<02:11,  1.22s/it] \n",
            "Attention Walk (Loss=2.117):  39%|███▉      | 69/176 [01:27<02:06,  1.18s/it]\n",
            "Attention Walk (Loss=2.1103):  39%|███▉      | 69/176 [01:28<02:06,  1.18s/it]\n",
            "Attention Walk (Loss=2.1103):  40%|███▉      | 70/176 [01:28<02:05,  1.18s/it]\n",
            "Attention Walk (Loss=2.1038):  40%|███▉      | 70/176 [01:29<02:05,  1.18s/it]\n",
            "Attention Walk (Loss=2.1038):  40%|████      | 71/176 [01:29<02:03,  1.17s/it]\n",
            "Attention Walk (Loss=2.0975):  40%|████      | 71/176 [01:30<02:03,  1.17s/it]\n",
            "Attention Walk (Loss=2.0975):  41%|████      | 72/176 [01:30<02:01,  1.16s/it]\n",
            "Attention Walk (Loss=2.0913):  41%|████      | 72/176 [01:31<02:01,  1.16s/it]\n",
            "Attention Walk (Loss=2.0913):  41%|████▏     | 73/176 [01:31<02:03,  1.19s/it]\n",
            "Attention Walk (Loss=2.0854):  41%|████▏     | 73/176 [01:33<02:03,  1.19s/it]\n",
            "Attention Walk (Loss=2.0854):  42%|████▏     | 74/176 [01:33<01:58,  1.16s/it]\n",
            "Attention Walk (Loss=2.0796):  42%|████▏     | 74/176 [01:34<01:58,  1.16s/it]\n",
            "Attention Walk (Loss=2.0796):  43%|████▎     | 75/176 [01:34<01:56,  1.16s/it]\n",
            "Attention Walk (Loss=2.0739):  43%|████▎     | 75/176 [01:35<01:56,  1.16s/it]\n",
            "Attention Walk (Loss=2.0739):  43%|████▎     | 76/176 [01:35<01:57,  1.18s/it]\n",
            "Attention Walk (Loss=2.0684):  43%|████▎     | 76/176 [01:36<01:57,  1.18s/it]\n",
            "Attention Walk (Loss=2.0684):  44%|████▍     | 77/176 [01:36<01:58,  1.20s/it]\n",
            "Attention Walk (Loss=2.063):  44%|████▍     | 77/176 [01:37<01:58,  1.20s/it] \n",
            "Attention Walk (Loss=2.063):  44%|████▍     | 78/176 [01:37<01:54,  1.17s/it]\n",
            "Attention Walk (Loss=2.0578):  44%|████▍     | 78/176 [01:38<01:54,  1.17s/it]\n",
            "Attention Walk (Loss=2.0578):  45%|████▍     | 79/176 [01:38<01:51,  1.15s/it]\n",
            "Attention Walk (Loss=2.0527):  45%|████▍     | 79/176 [01:39<01:51,  1.15s/it]\n",
            "Attention Walk (Loss=2.0527):  45%|████▌     | 80/176 [01:39<01:49,  1.14s/it]\n",
            "Attention Walk (Loss=2.0478):  45%|████▌     | 80/176 [01:41<01:49,  1.14s/it]\n",
            "Attention Walk (Loss=2.0478):  46%|████▌     | 81/176 [01:41<01:48,  1.15s/it]\n",
            "Attention Walk (Loss=2.043):  46%|████▌     | 81/176 [01:42<01:48,  1.15s/it] \n",
            "Attention Walk (Loss=2.043):  47%|████▋     | 82/176 [01:42<01:46,  1.14s/it]\n",
            "Attention Walk (Loss=2.0382):  47%|████▋     | 82/176 [01:43<01:46,  1.14s/it]\n",
            "Attention Walk (Loss=2.0382):  47%|████▋     | 83/176 [01:43<01:46,  1.14s/it]\n",
            "Attention Walk (Loss=2.0336):  47%|████▋     | 83/176 [01:44<01:46,  1.14s/it]\n",
            "Attention Walk (Loss=2.0336):  48%|████▊     | 84/176 [01:44<01:49,  1.20s/it]\n",
            "Attention Walk (Loss=2.0291):  48%|████▊     | 84/176 [01:45<01:49,  1.20s/it]\n",
            "Attention Walk (Loss=2.0291):  48%|████▊     | 85/176 [01:45<01:47,  1.18s/it]\n",
            "Attention Walk (Loss=2.0248):  48%|████▊     | 85/176 [01:47<01:47,  1.18s/it]\n",
            "Attention Walk (Loss=2.0248):  49%|████▉     | 86/176 [01:47<01:46,  1.19s/it]\n",
            "Attention Walk (Loss=2.0205):  49%|████▉     | 86/176 [01:48<01:46,  1.19s/it]\n",
            "Attention Walk (Loss=2.0205):  49%|████▉     | 87/176 [01:48<01:44,  1.17s/it]\n",
            "Attention Walk (Loss=2.0163):  49%|████▉     | 87/176 [01:49<01:44,  1.17s/it]\n",
            "Attention Walk (Loss=2.0163):  50%|█████     | 88/176 [01:49<01:44,  1.19s/it]\n",
            "Attention Walk (Loss=2.0122):  50%|█████     | 88/176 [01:50<01:44,  1.19s/it]\n",
            "Attention Walk (Loss=2.0122):  51%|█████     | 89/176 [01:50<01:42,  1.17s/it]\n",
            "Attention Walk (Loss=2.0082):  51%|█████     | 89/176 [01:51<01:42,  1.17s/it]\n",
            "Attention Walk (Loss=2.0082):  51%|█████     | 90/176 [01:51<01:39,  1.16s/it]\n",
            "Attention Walk (Loss=2.0043):  51%|█████     | 90/176 [01:52<01:39,  1.16s/it]\n",
            "Attention Walk (Loss=2.0043):  52%|█████▏    | 91/176 [01:52<01:39,  1.17s/it]\n",
            "Attention Walk (Loss=2.0004):  52%|█████▏    | 91/176 [01:54<01:39,  1.17s/it]\n",
            "Attention Walk (Loss=2.0004):  52%|█████▏    | 92/176 [01:54<01:38,  1.17s/it]\n",
            "Attention Walk (Loss=1.9967):  52%|█████▏    | 92/176 [01:55<01:38,  1.17s/it]\n",
            "Attention Walk (Loss=1.9967):  53%|█████▎    | 93/176 [01:55<01:37,  1.17s/it]\n",
            "Attention Walk (Loss=1.993):  53%|█████▎    | 93/176 [01:56<01:37,  1.17s/it] \n",
            "Attention Walk (Loss=1.993):  53%|█████▎    | 94/176 [01:56<01:35,  1.16s/it]\n",
            "Attention Walk (Loss=1.9894):  53%|█████▎    | 94/176 [01:57<01:35,  1.16s/it]\n",
            "Attention Walk (Loss=1.9894):  54%|█████▍    | 95/176 [01:57<01:32,  1.15s/it]\n",
            "Attention Walk (Loss=1.9859):  54%|█████▍    | 95/176 [01:58<01:32,  1.15s/it]\n",
            "Attention Walk (Loss=1.9859):  55%|█████▍    | 96/176 [01:58<01:29,  1.12s/it]\n",
            "Attention Walk (Loss=1.9824):  55%|█████▍    | 96/176 [01:59<01:29,  1.12s/it]\n",
            "Attention Walk (Loss=1.9824):  55%|█████▌    | 97/176 [01:59<01:29,  1.13s/it]\n",
            "Attention Walk (Loss=1.979):  55%|█████▌    | 97/176 [02:00<01:29,  1.13s/it] \n",
            "Attention Walk (Loss=1.979):  56%|█████▌    | 98/176 [02:00<01:27,  1.12s/it]\n",
            "Attention Walk (Loss=1.9757):  56%|█████▌    | 98/176 [02:01<01:27,  1.12s/it]\n",
            "Attention Walk (Loss=1.9757):  56%|█████▋    | 99/176 [02:01<01:25,  1.11s/it]\n",
            "Attention Walk (Loss=1.9724):  56%|█████▋    | 99/176 [02:02<01:25,  1.11s/it]\n",
            "Attention Walk (Loss=1.9724):  57%|█████▋    | 100/176 [02:02<01:23,  1.10s/it]\n",
            "Attention Walk (Loss=1.9692):  57%|█████▋    | 100/176 [02:04<01:23,  1.10s/it]\n",
            "Attention Walk (Loss=1.9692):  57%|█████▋    | 101/176 [02:04<01:21,  1.09s/it]\n",
            "Attention Walk (Loss=1.966):  57%|█████▋    | 101/176 [02:05<01:21,  1.09s/it] \n",
            "Attention Walk (Loss=1.966):  58%|█████▊    | 102/176 [02:05<01:20,  1.09s/it]\n",
            "Attention Walk (Loss=1.9629):  58%|█████▊    | 102/176 [02:06<01:20,  1.09s/it]\n",
            "Attention Walk (Loss=1.9629):  59%|█████▊    | 103/176 [02:06<01:19,  1.08s/it]\n",
            "Attention Walk (Loss=1.9598):  59%|█████▊    | 103/176 [02:07<01:19,  1.08s/it]\n",
            "Attention Walk (Loss=1.9598):  59%|█████▉    | 104/176 [02:07<01:17,  1.07s/it]\n",
            "Attention Walk (Loss=1.9568):  59%|█████▉    | 104/176 [02:08<01:17,  1.07s/it]\n",
            "Attention Walk (Loss=1.9568):  60%|█████▉    | 105/176 [02:08<01:14,  1.05s/it]\n",
            "Attention Walk (Loss=1.9539):  60%|█████▉    | 105/176 [02:09<01:14,  1.05s/it]\n",
            "Attention Walk (Loss=1.9539):  60%|██████    | 106/176 [02:09<01:13,  1.05s/it]\n",
            "Attention Walk (Loss=1.951):  60%|██████    | 106/176 [02:10<01:13,  1.05s/it] \n",
            "Attention Walk (Loss=1.951):  61%|██████    | 107/176 [02:10<01:12,  1.04s/it]\n",
            "Attention Walk (Loss=1.9481):  61%|██████    | 107/176 [02:11<01:12,  1.04s/it]\n",
            "Attention Walk (Loss=1.9481):  61%|██████▏   | 108/176 [02:11<01:10,  1.04s/it]\n",
            "Attention Walk (Loss=1.9453):  61%|██████▏   | 108/176 [02:12<01:10,  1.04s/it]\n",
            "Attention Walk (Loss=1.9453):  62%|██████▏   | 109/176 [02:12<01:10,  1.06s/it]\n",
            "Attention Walk (Loss=1.9426):  62%|██████▏   | 109/176 [02:13<01:10,  1.06s/it]\n",
            "Attention Walk (Loss=1.9426):  62%|██████▎   | 110/176 [02:13<01:08,  1.04s/it]\n",
            "Attention Walk (Loss=1.9399):  62%|██████▎   | 110/176 [02:14<01:08,  1.04s/it]\n",
            "Attention Walk (Loss=1.9399):  63%|██████▎   | 111/176 [02:14<01:07,  1.05s/it]\n",
            "Attention Walk (Loss=1.9372):  63%|██████▎   | 111/176 [02:15<01:07,  1.05s/it]\n",
            "Attention Walk (Loss=1.9372):  64%|██████▎   | 112/176 [02:15<01:07,  1.05s/it]\n",
            "Attention Walk (Loss=1.9346):  64%|██████▎   | 112/176 [02:16<01:07,  1.05s/it]\n",
            "Attention Walk (Loss=1.9346):  64%|██████▍   | 113/176 [02:16<01:07,  1.06s/it]\n",
            "Attention Walk (Loss=1.932):  64%|██████▍   | 113/176 [02:17<01:07,  1.06s/it] \n",
            "Attention Walk (Loss=1.932):  65%|██████▍   | 114/176 [02:17<01:05,  1.06s/it]\n",
            "Attention Walk (Loss=1.9295):  65%|██████▍   | 114/176 [02:18<01:05,  1.06s/it]\n",
            "Attention Walk (Loss=1.9295):  65%|██████▌   | 115/176 [02:18<01:04,  1.05s/it]\n",
            "Attention Walk (Loss=1.927):  65%|██████▌   | 115/176 [02:19<01:04,  1.05s/it] \n",
            "Attention Walk (Loss=1.927):  66%|██████▌   | 116/176 [02:19<01:02,  1.04s/it]\n",
            "Attention Walk (Loss=1.9246):  66%|██████▌   | 116/176 [02:20<01:02,  1.04s/it]\n",
            "Attention Walk (Loss=1.9246):  66%|██████▋   | 117/176 [02:20<01:01,  1.03s/it]\n",
            "Attention Walk (Loss=1.9221):  66%|██████▋   | 117/176 [02:21<01:01,  1.03s/it]\n",
            "Attention Walk (Loss=1.9221):  67%|██████▋   | 118/176 [02:21<00:59,  1.03s/it]\n",
            "Attention Walk (Loss=1.9198):  67%|██████▋   | 118/176 [02:22<00:59,  1.03s/it]\n",
            "Attention Walk (Loss=1.9198):  68%|██████▊   | 119/176 [02:22<00:58,  1.03s/it]\n",
            "Attention Walk (Loss=1.9174):  68%|██████▊   | 119/176 [02:23<00:58,  1.03s/it]\n",
            "Attention Walk (Loss=1.9174):  68%|██████▊   | 120/176 [02:23<00:57,  1.02s/it]\n",
            "Attention Walk (Loss=1.9151):  68%|██████▊   | 120/176 [02:24<00:57,  1.02s/it]\n",
            "Attention Walk (Loss=1.9151):  69%|██████▉   | 121/176 [02:24<00:56,  1.02s/it]\n",
            "Attention Walk (Loss=1.9129):  69%|██████▉   | 121/176 [02:25<00:56,  1.02s/it]\n",
            "Attention Walk (Loss=1.9129):  69%|██████▉   | 122/176 [02:25<00:54,  1.02s/it]\n",
            "Attention Walk (Loss=1.9107):  69%|██████▉   | 122/176 [02:26<00:54,  1.02s/it]\n",
            "Attention Walk (Loss=1.9107):  70%|██████▉   | 123/176 [02:26<00:53,  1.02s/it]\n",
            "Attention Walk (Loss=1.9085):  70%|██████▉   | 123/176 [02:27<00:53,  1.02s/it]\n",
            "Attention Walk (Loss=1.9085):  70%|███████   | 124/176 [02:27<00:52,  1.01s/it]\n",
            "Attention Walk (Loss=1.9063):  70%|███████   | 124/176 [02:28<00:52,  1.01s/it]\n",
            "Attention Walk (Loss=1.9063):  71%|███████   | 125/176 [02:28<00:51,  1.02s/it]\n",
            "Attention Walk (Loss=1.9042):  71%|███████   | 125/176 [02:29<00:51,  1.02s/it]\n",
            "Attention Walk (Loss=1.9042):  72%|███████▏  | 126/176 [02:29<00:50,  1.02s/it]\n",
            "Attention Walk (Loss=1.9021):  72%|███████▏  | 126/176 [02:30<00:50,  1.02s/it]\n",
            "Attention Walk (Loss=1.9021):  72%|███████▏  | 127/176 [02:30<00:49,  1.02s/it]\n",
            "Attention Walk (Loss=1.9001):  72%|███████▏  | 127/176 [02:31<00:49,  1.02s/it]\n",
            "Attention Walk (Loss=1.9001):  73%|███████▎  | 128/176 [02:31<00:48,  1.02s/it]\n",
            "Attention Walk (Loss=1.8981):  73%|███████▎  | 128/176 [02:33<00:48,  1.02s/it]\n",
            "Attention Walk (Loss=1.8981):  73%|███████▎  | 129/176 [02:33<00:48,  1.03s/it]\n",
            "Attention Walk (Loss=1.8961):  73%|███████▎  | 129/176 [02:34<00:48,  1.03s/it]\n",
            "Attention Walk (Loss=1.8961):  74%|███████▍  | 130/176 [02:34<00:48,  1.06s/it]\n",
            "Attention Walk (Loss=1.8942):  74%|███████▍  | 130/176 [02:35<00:48,  1.06s/it]\n",
            "Attention Walk (Loss=1.8942):  74%|███████▍  | 131/176 [02:35<00:46,  1.04s/it]\n",
            "Attention Walk (Loss=1.8922):  74%|███████▍  | 131/176 [02:36<00:46,  1.04s/it]\n",
            "Attention Walk (Loss=1.8922):  75%|███████▌  | 132/176 [02:36<00:45,  1.03s/it]\n",
            "Attention Walk (Loss=1.8903):  75%|███████▌  | 132/176 [02:37<00:45,  1.03s/it]\n",
            "Attention Walk (Loss=1.8903):  76%|███████▌  | 133/176 [02:37<00:44,  1.03s/it]\n",
            "Attention Walk (Loss=1.8885):  76%|███████▌  | 133/176 [02:38<00:44,  1.03s/it]\n",
            "Attention Walk (Loss=1.8885):  76%|███████▌  | 134/176 [02:38<00:43,  1.04s/it]\n",
            "Attention Walk (Loss=1.8866):  76%|███████▌  | 134/176 [02:39<00:43,  1.04s/it]\n",
            "Attention Walk (Loss=1.8866):  77%|███████▋  | 135/176 [02:39<00:42,  1.04s/it]\n",
            "Attention Walk (Loss=1.8848):  77%|███████▋  | 135/176 [02:40<00:42,  1.04s/it]\n",
            "Attention Walk (Loss=1.8848):  77%|███████▋  | 136/176 [02:40<00:41,  1.03s/it]\n",
            "Attention Walk (Loss=1.8831):  77%|███████▋  | 136/176 [02:41<00:41,  1.03s/it]\n",
            "Attention Walk (Loss=1.8831):  78%|███████▊  | 137/176 [02:41<00:39,  1.01s/it]\n",
            "Attention Walk (Loss=1.8813):  78%|███████▊  | 137/176 [02:42<00:39,  1.01s/it]\n",
            "Attention Walk (Loss=1.8813):  78%|███████▊  | 138/176 [02:42<00:38,  1.01s/it]\n",
            "Attention Walk (Loss=1.8796):  78%|███████▊  | 138/176 [02:43<00:38,  1.01s/it]\n",
            "Attention Walk (Loss=1.8796):  79%|███████▉  | 139/176 [02:43<00:37,  1.01s/it]\n",
            "Attention Walk (Loss=1.8779):  79%|███████▉  | 139/176 [02:44<00:37,  1.01s/it]\n",
            "Attention Walk (Loss=1.8779):  80%|███████▉  | 140/176 [02:44<00:36,  1.01s/it]\n",
            "Attention Walk (Loss=1.8762):  80%|███████▉  | 140/176 [02:45<00:36,  1.01s/it]\n",
            "Attention Walk (Loss=1.8762):  80%|████████  | 141/176 [02:45<00:35,  1.01s/it]\n",
            "Attention Walk (Loss=1.8746):  80%|████████  | 141/176 [02:46<00:35,  1.01s/it]\n",
            "Attention Walk (Loss=1.8746):  81%|████████  | 142/176 [02:46<00:34,  1.01s/it]\n",
            "Attention Walk (Loss=1.873):  81%|████████  | 142/176 [02:47<00:34,  1.01s/it] \n",
            "Attention Walk (Loss=1.873):  81%|████████▏ | 143/176 [02:47<00:34,  1.03s/it]\n",
            "Attention Walk (Loss=1.8714):  81%|████████▏ | 143/176 [02:48<00:34,  1.03s/it]\n",
            "Attention Walk (Loss=1.8714):  82%|████████▏ | 144/176 [02:48<00:32,  1.03s/it]\n",
            "Attention Walk (Loss=1.8698):  82%|████████▏ | 144/176 [02:49<00:32,  1.03s/it]\n",
            "Attention Walk (Loss=1.8698):  82%|████████▏ | 145/176 [02:49<00:31,  1.02s/it]\n",
            "Attention Walk (Loss=1.8682):  82%|████████▏ | 145/176 [02:50<00:31,  1.02s/it]\n",
            "Attention Walk (Loss=1.8682):  83%|████████▎ | 146/176 [02:50<00:31,  1.04s/it]\n",
            "Attention Walk (Loss=1.8667):  83%|████████▎ | 146/176 [02:51<00:31,  1.04s/it]\n",
            "Attention Walk (Loss=1.8667):  84%|████████▎ | 147/176 [02:51<00:29,  1.03s/it]\n",
            "Attention Walk (Loss=1.8652):  84%|████████▎ | 147/176 [02:52<00:29,  1.03s/it]\n",
            "Attention Walk (Loss=1.8652):  84%|████████▍ | 148/176 [02:52<00:28,  1.03s/it]\n",
            "Attention Walk (Loss=1.8637):  84%|████████▍ | 148/176 [02:53<00:28,  1.03s/it]\n",
            "Attention Walk (Loss=1.8637):  85%|████████▍ | 149/176 [02:53<00:27,  1.03s/it]\n",
            "Attention Walk (Loss=1.8623):  85%|████████▍ | 149/176 [02:54<00:27,  1.03s/it]\n",
            "Attention Walk (Loss=1.8623):  85%|████████▌ | 150/176 [02:54<00:26,  1.03s/it]\n",
            "Attention Walk (Loss=1.8608):  85%|████████▌ | 150/176 [02:55<00:26,  1.03s/it]\n",
            "Attention Walk (Loss=1.8608):  86%|████████▌ | 151/176 [02:55<00:25,  1.02s/it]\n",
            "Attention Walk (Loss=1.8594):  86%|████████▌ | 151/176 [02:56<00:25,  1.02s/it]\n",
            "Attention Walk (Loss=1.8594):  86%|████████▋ | 152/176 [02:56<00:24,  1.02s/it]\n",
            "Attention Walk (Loss=1.858):  86%|████████▋ | 152/176 [02:57<00:24,  1.02s/it] \n",
            "Attention Walk (Loss=1.858):  87%|████████▋ | 153/176 [02:57<00:23,  1.03s/it]\n",
            "Attention Walk (Loss=1.8566):  87%|████████▋ | 153/176 [02:58<00:23,  1.03s/it]\n",
            "Attention Walk (Loss=1.8566):  88%|████████▊ | 154/176 [02:58<00:22,  1.03s/it]\n",
            "Attention Walk (Loss=1.8553):  88%|████████▊ | 154/176 [02:59<00:22,  1.03s/it]\n",
            "Attention Walk (Loss=1.8553):  88%|████████▊ | 155/176 [02:59<00:21,  1.04s/it]\n",
            "Attention Walk (Loss=1.8539):  88%|████████▊ | 155/176 [03:00<00:21,  1.04s/it]\n",
            "Attention Walk (Loss=1.8539):  89%|████████▊ | 156/176 [03:00<00:20,  1.03s/it]\n",
            "Attention Walk (Loss=1.8526):  89%|████████▊ | 156/176 [03:01<00:20,  1.03s/it]\n",
            "Attention Walk (Loss=1.8526):  89%|████████▉ | 157/176 [03:01<00:19,  1.03s/it]\n",
            "Attention Walk (Loss=1.8513):  89%|████████▉ | 157/176 [03:02<00:19,  1.03s/it]\n",
            "Attention Walk (Loss=1.8513):  90%|████████▉ | 158/176 [03:02<00:18,  1.03s/it]\n",
            "Attention Walk (Loss=1.85):  90%|████████▉ | 158/176 [03:03<00:18,  1.03s/it]  \n",
            "Attention Walk (Loss=1.85):  90%|█████████ | 159/176 [03:03<00:17,  1.03s/it]\n",
            "Attention Walk (Loss=1.8487):  90%|█████████ | 159/176 [03:04<00:17,  1.03s/it]\n",
            "Attention Walk (Loss=1.8487):  91%|█████████ | 160/176 [03:04<00:16,  1.03s/it]\n",
            "Attention Walk (Loss=1.8475):  91%|█████████ | 160/176 [03:05<00:16,  1.03s/it]\n",
            "Attention Walk (Loss=1.8475):  91%|█████████▏| 161/176 [03:05<00:15,  1.03s/it]\n",
            "Attention Walk (Loss=1.8463):  91%|█████████▏| 161/176 [03:07<00:15,  1.03s/it]\n",
            "Attention Walk (Loss=1.8463):  92%|█████████▏| 162/176 [03:07<00:15,  1.08s/it]\n",
            "Attention Walk (Loss=1.845):  92%|█████████▏| 162/176 [03:08<00:15,  1.08s/it] \n",
            "Attention Walk (Loss=1.845):  93%|█████████▎| 163/176 [03:08<00:15,  1.16s/it]\n",
            "Attention Walk (Loss=1.8438):  93%|█████████▎| 163/176 [03:09<00:15,  1.16s/it]\n",
            "Attention Walk (Loss=1.8438):  93%|█████████▎| 164/176 [03:09<00:13,  1.15s/it]\n",
            "Attention Walk (Loss=1.8427):  93%|█████████▎| 164/176 [03:10<00:13,  1.15s/it]\n",
            "Attention Walk (Loss=1.8427):  94%|█████████▍| 165/176 [03:10<00:12,  1.10s/it]\n",
            "Attention Walk (Loss=1.8415):  94%|█████████▍| 165/176 [03:11<00:12,  1.10s/it]\n",
            "Attention Walk (Loss=1.8415):  94%|█████████▍| 166/176 [03:11<00:10,  1.09s/it]\n",
            "Attention Walk (Loss=1.8403):  94%|█████████▍| 166/176 [03:12<00:10,  1.09s/it]\n",
            "Attention Walk (Loss=1.8403):  95%|█████████▍| 167/176 [03:12<00:09,  1.07s/it]\n",
            "Attention Walk (Loss=1.8392):  95%|█████████▍| 167/176 [03:13<00:09,  1.07s/it]\n",
            "Attention Walk (Loss=1.8392):  95%|█████████▌| 168/176 [03:13<00:08,  1.09s/it]\n",
            "Attention Walk (Loss=1.8381):  95%|█████████▌| 168/176 [03:14<00:08,  1.09s/it]\n",
            "Attention Walk (Loss=1.8381):  96%|█████████▌| 169/176 [03:14<00:07,  1.09s/it]\n",
            "Attention Walk (Loss=1.837):  96%|█████████▌| 169/176 [03:15<00:07,  1.09s/it] \n",
            "Attention Walk (Loss=1.837):  97%|█████████▋| 170/176 [03:15<00:06,  1.08s/it]\n",
            "Attention Walk (Loss=1.8359):  97%|█████████▋| 170/176 [03:17<00:06,  1.08s/it]\n",
            "Attention Walk (Loss=1.8359):  97%|█████████▋| 171/176 [03:17<00:05,  1.12s/it]\n",
            "Attention Walk (Loss=1.8348):  97%|█████████▋| 171/176 [03:18<00:05,  1.12s/it]\n",
            "Attention Walk (Loss=1.8348):  98%|█████████▊| 172/176 [03:18<00:04,  1.15s/it]\n",
            "Attention Walk (Loss=1.8337):  98%|█████████▊| 172/176 [03:19<00:04,  1.15s/it]\n",
            "Attention Walk (Loss=1.8337):  98%|█████████▊| 173/176 [03:19<00:03,  1.16s/it]\n",
            "Attention Walk (Loss=1.8327):  98%|█████████▊| 173/176 [03:20<00:03,  1.16s/it]\n",
            "Attention Walk (Loss=1.8327):  99%|█████████▉| 174/176 [03:20<00:02,  1.16s/it]\n",
            "Attention Walk (Loss=1.8317):  99%|█████████▉| 174/176 [03:22<00:02,  1.16s/it]\n",
            "Attention Walk (Loss=1.8317):  99%|█████████▉| 175/176 [03:22<00:01,  1.23s/it]\n",
            "Attention Walk (Loss=1.8306):  99%|█████████▉| 175/176 [03:23<00:01,  1.23s/it]\n",
            "Attention Walk (Loss=1.8306): 100%|██████████| 176/176 [03:23<00:00,  1.30s/it]\n",
            "Attention Walk (Loss=1.8306): 100%|██████████| 176/176 [03:23<00:00,  1.16s/it]\n"
          ]
        }
      ],
      "source": [
        "!cd AttentionWalk && python src/main.py --edge-path ../../data/facebook_edges.csv --embedding-path ../../result/facebook_embeddings_attention.csv --attention-path ../../result/facebook_attention.csv --epochs 176"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de1c81e3",
      "metadata": {
        "id": "de1c81e3"
      },
      "source": [
        "## Test with the citation network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab1dc864",
      "metadata": {
        "id": "ab1dc864",
        "outputId": "a9337ff5-b81b-407b-80a2-072176a06703"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------+-------------------------------------------------+"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pietr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\_data.py:117: RuntimeWarning: divide by zero encountered in power\n",
            "  return self._with_data(data ** n)\n",
            "\n",
            "Adjacency matrix powers:   0%|          | 0/4 [00:00<?, ?it/s]\n",
            "Adjacency matrix powers:  25%|██▌       | 1/4 [00:58<02:55, 58.59s/it]\n",
            "Adjacency matrix powers:  50%|█████     | 2/4 [09:43<11:05, 332.86s/it]\n",
            "Adjacency matrix powers:  50%|█████     | 2/4 [12:48<12:48, 384.18s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\pietr\\Desktop\\lfn_project\\src\\AttentionWalk\\src\\main.py\", line 19, in <module>\n",
            "    main()\n",
            "  File \"c:\\Users\\pietr\\Desktop\\lfn_project\\src\\AttentionWalk\\src\\main.py\", line 14, in main\n",
            "    model = AttentionWalkTrainer(args)\n",
            "  File \"c:\\Users\\pietr\\Desktop\\lfn_project\\src\\AttentionWalk\\src\\attentionwalk.py\", line 77, in __init__\n",
            "    self.initialize_model_and_features()\n",
            "  File \"c:\\Users\\pietr\\Desktop\\lfn_project\\src\\AttentionWalk\\src\\attentionwalk.py\", line 83, in initialize_model_and_features\n",
            "    self.target_tensor = feature_calculator(self.args, self.graph)\n",
            "  File \"c:\\Users\\pietr\\Desktop\\lfn_project\\src\\AttentionWalk\\src\\utils.py\", line 55, in feature_calculator\n",
            "    powered_A = powered_A.dot(normalized_adjacency_matrix)\n",
            "  File \"c:\\Users\\pietr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\_base.py\", line 416, in dot\n",
            "    return self @ other\n",
            "  File \"c:\\Users\\pietr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\_base.py\", line 630, in __matmul__\n",
            "    return self._mul_dispatch(other)\n",
            "  File \"c:\\Users\\pietr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\_base.py\", line 541, in _mul_dispatch\n",
            "    return self._mul_sparse_matrix(other)\n",
            "  File \"c:\\Users\\pietr\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\_compressed.py\", line 529, in _mul_sparse_matrix\n",
            "    indices = np.empty(nnz, dtype=idx_dtype)\n",
            "numpy.core._exceptions.MemoryError: Unable to allocate 1.90 GiB for an array with shape (510551992,) and data type int32\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "| Attention path |      ../../result/cit-HepTh_attention.csv       |\n",
            "+================+=================================================+\n",
            "| Beta           | 0.500                                           |\n",
            "+----------------+-------------------------------------------------+\n",
            "| Dimensions     | 128                                             |\n",
            "+----------------+-------------------------------------------------+\n",
            "| Edge path      | ../../data/cit-HepTh_edges.csv                  |\n",
            "+----------------+-------------------------------------------------+\n",
            "| Embedding path | ../../result/cit-HepTh_embeddings_attention.csv |\n",
            "+----------------+-------------------------------------------------+\n",
            "| Epochs         | 176                                             |\n",
            "+----------------+-------------------------------------------------+\n",
            "| Gamma          | 0.500                                           |\n",
            "+----------------+-------------------------------------------------+\n",
            "| Learning rate  | 0.010                                           |\n",
            "+----------------+-------------------------------------------------+\n",
            "| Num of walks   | 80                                              |\n",
            "+----------------+-------------------------------------------------+\n",
            "| Window size    | 5                                               |\n",
            "+----------------+-------------------------------------------------+\n",
            "\n",
            "Target matrix creation started.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!cd AttentionWalk && python src/main.py --edge-path ../../data/cit-HepTh_edges.csv --embedding-path ../../result/cit-HepTh_embeddings_attention.csv --attention-path ../../result/cit-HepTh_attention.csv --epochs 176"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with the biological network"
      ],
      "metadata": {
        "id": "P2KVPWY9ovVm"
      },
      "id": "P2KVPWY9ovVm"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd AttentionWalk && python src/main.py --edge-path ../bio-CE-CX_edges.csv --embedding-path ../result/bio-CE-CX_embeddings_attention.csv --attention-path ../result/bio-CE-CX_attention.csv"
      ],
      "metadata": {
        "id": "-URjbGoLozuS",
        "outputId": "17f2f3d5-e0ad-49dd-ffb1-760414c60dec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-URjbGoLozuS",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------------------------------------+\n",
            "| Attention path |      ../result/bio-CE-CX_attention.csv       |\n",
            "+================+==============================================+\n",
            "| Beta           | 0.500                                        |\n",
            "+----------------+----------------------------------------------+\n",
            "| Dimensions     | 128                                          |\n",
            "+----------------+----------------------------------------------+\n",
            "| Edge path      | ../bio-CE-CX_edges.csv                       |\n",
            "+----------------+----------------------------------------------+\n",
            "| Embedding path | ../result/bio-CE-CX_embeddings_attention.csv |\n",
            "+----------------+----------------------------------------------+\n",
            "| Epochs         | 200                                          |\n",
            "+----------------+----------------------------------------------+\n",
            "| Gamma          | 0.500                                        |\n",
            "+----------------+----------------------------------------------+\n",
            "| Learning rate  | 0.010                                        |\n",
            "+----------------+----------------------------------------------+\n",
            "| Num of walks   | 80                                           |\n",
            "+----------------+----------------------------------------------+\n",
            "| Window size    | 5                                            |\n",
            "+----------------+----------------------------------------------+\n",
            "\n",
            "Target matrix creation started.\n",
            "\n",
            "Adjacency matrix powers: 100% 4/4 [01:31<00:00, 22.79s/it]\n",
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}